{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a195ef13",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install accelerate\n",
    "!pip install einops\n",
    "!pip install bitsandbytes\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a2474ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/bitsandbytes/cextension.py:34: UserWarning: The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n",
      "  warn(\"The installed version of bitsandbytes was compiled without GPU support. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf8edd135984bdb9c7141e362337abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99bffb22eea04841a2e5e3e0499240ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (â€¦)neration_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "model_name = \"MBZUAI/LaMini-T5-738M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name, device_map = \"auto\", torch_dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b2e89da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langchain.llms import HuggingFacePipeline\n",
    "\n",
    "pipeline = pipeline(\n",
    "  \"text2text-generation\",\n",
    "  model = model,\n",
    "  tokenizer = tokenizer,\n",
    "  max_length = 256,\n",
    "  do_sample = True,\n",
    "  temperature = 0.3,\n",
    "  top_p = 0.95\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline = pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ace0209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write me a section title for deploying a model on SageMaker and generated an endpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3e55e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"SageMaker Model Deployment and Endpoint Generation\"'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_text = llm(prompt)\n",
    "generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660a9e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------!"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Blockchain is a decentralized digital ledger that records transactions in a secure and transparent manner.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel, get_huggingface_llm_image_uri\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'MBZUAI/LaMini-T5-738M',\n",
    "    'HF_TASK': 'text2text-generation',\n",
    "    'device_map': 'auto',\n",
    "    'torch_dtype': 'torch.float32'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\timage_uri=get_huggingface_llm_image_uri(\"huggingface\",version=\"0.8.2\"),\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1,\n",
    "\tinstance_type=\"ml.g4dn.xlarge\",\n",
    "  )\n",
    "  \n",
    "# send request\n",
    "predictor.predict({\n",
    "\t\"inputs\": \"Write a short article on Blockchain?\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "524f798a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface-pytorch-tgi-inference-2023-07-16-14-08-59-732\n"
     ]
    }
   ],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "print(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f4bf74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Write an article on Large Language Models\"\n",
    "\n",
    "# hyperparameter payload\n",
    "payload = {\n",
    "    \"inputs\": prompt,\n",
    "    \"parameters\": {\n",
    "        \"do_sample\": True,\n",
    "        \"top_p\": 0.7,\n",
    "        \"temperature\": 0.3,\n",
    "        \"top_k\": 50,\n",
    "        \"max_new_tokens\": 512,\n",
    "        \"repetition_penalty\": 1.03\n",
    "    }\n",
    "}\n",
    "\n",
    "runtime = boto3.client(\"runtime.sagemaker\")\n",
    "response = runtime.invoke_endpoint(EndpointName=endpoint_name, ContentType=\"application/json\", Body= json.dumps(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a825988d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '9610fc4e-1dc7-4fd6-b909-ef1692c5d8a8',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '9610fc4e-1dc7-4fd6-b909-ef1692c5d8a8',\n",
       "   'x-amzn-invoked-production-variant': 'AllTraffic',\n",
       "   'date': 'Sun, 16 Jul 2023 14:31:19 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '672',\n",
       "   'connection': 'keep-alive'},\n",
       "  'RetryAttempts': 0},\n",
       " 'ContentType': 'application/json',\n",
       " 'InvokedProductionVariant': 'AllTraffic',\n",
       " 'Body': <botocore.response.StreamingBody at 0x7f67434741c0>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "455def88",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = json.loads(response[\"Body\"].read().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91cd0588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'generated_text': 'Large Language Models (LLMs) are a type of machine learning algorithm that is used to analyze large amounts of text data. These models are designed to recognize patterns and make predictions based on the linguistic features of the text. LLMs are widely used in various applications, including speech recognition, sentiment analysis, and machine translation. One of the most significant advantages of LLMs is their ability to handle large amounts of text data. They can process large amounts of text data quickly and accurately, allowing them to understand and generate coherent sentences. However, they can be computationally expensive to train and maintain, and'}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8e7510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa1f6c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
